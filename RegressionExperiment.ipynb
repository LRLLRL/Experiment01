{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load regretion.py\n",
    "#!/usr/bin/env python2\n",
    "\"\"\"\n",
    "Created on Sat Dec  9 19:32:01 2017\n",
    "\n",
    "@author: lrl\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x,y=load_svmlight_file(\"/home/lrl/ML-logits/housing_scale\")\n",
    "x=x.todense()\n",
    "\n",
    "m,n=np.shape(x)\n",
    "y=y.reshape((m,1))\n",
    "x_data=np.ones((m,n+1))\n",
    "x_data[:,:-1]=x[:,:]\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(x_data,y,test_size=0.2)\n",
    "\n",
    "\n",
    "theta=np.ones((n+1,1)) \n",
    "    \n",
    " \n",
    "def batchGradienDenscent(epoch,x,y,theta,learning_rate):\n",
    "    Cost=[]\n",
    "    for i in range(0,epoch):\n",
    "      \n",
    "        hypothesis=np.dot(x,theta)\n",
    "        #print hypothesis.shape\n",
    "        loss=hypothesis-y\n",
    "        #print loss.shape\n",
    "        gradient=np.dot(x.T,loss)/m\n",
    "        #print(gradient.shape)\n",
    "        theta=theta-learning_rate*gradient\n",
    "        \n",
    "        #print(theta.shape)\n",
    "        #cost=np.average(np.abs(np.dot(x,theta)-y))\n",
    "        cost=1.0/2/m*np.sum(np.square(np.dot(x,theta)-y))\n",
    "        print cost\n",
    "        Cost.append(cost)\n",
    "    #print Cost\n",
    "       \n",
    "    return Cost,theta\n",
    "    \n",
    "\n",
    "learning_rate=0.05\n",
    "epoch=200\n",
    "\n",
    "cost_train,theta = batchGradienDenscent(epoch,x_train,y_train,theta,learning_rate)\n",
    "#print theta\n",
    "cost_test,theta = batchGradienDenscent(epoch,x_test,y_test,theta,learning_rate)\n",
    "#print theta\n",
    "#,n=np.shape(x_test)\n",
    "#test=np.ones((m,n+1))\n",
    "#test[:,:-1]=x_test\n",
    "#pre=np.dot(x_test,theta)\n",
    "epoches=range(200)\n",
    "plt.figure(figsize=(18,20))\n",
    "plt.plot(epoches,cost_train,\"-\",color=\"r\",label=\"train loss\")\n",
    "plt.plot(epoches,cost_test,\"-\",color=\"b\",label=\"test loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
